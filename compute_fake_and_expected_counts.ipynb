{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d935769f",
   "metadata": {},
   "source": [
    "# This is notebook for extraction of the ON/OFF and expected counts (using the corresponding python script) from the datasets considering different models of photon-ALP mixing in the ALPs parameter space.\n",
    "\n",
    "### It was written by Giacomo D'Amico and Ivana Batković for the needs of the article \"Constraints on axion-like particles with the Perseus Galaxy Cluster with MAGIC\". \n",
    "\n",
    "### If you wish to use the script and reproduce the results, you are invited to contact the authors:\n",
    "\n",
    "### Giacomo D'Amico, giacomo.damico@uib.no\n",
    "### Ivana Batković, ivana.batkovic@phd.unipd.it\n",
    "\n",
    "\n",
    "### For running this script, gammapy-0.20 version is needed. In case you miss it, check: https://docs.gammapy.org/0.20/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c495814",
   "metadata": {},
   "source": [
    "# LOAD MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d42579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('xtick', labelsize=20)   \n",
    "plt.rc('ytick', labelsize=20)\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif',size=25)\n",
    "\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from regions import CircleSkyRegion, PointSkyRegion\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from functools import partial\n",
    "import scipy.special as scipys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6655a8e8",
   "metadata": {},
   "source": [
    "# GAMMAPY MODULES\n",
    "### gammapy 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.modeling import Fit\n",
    "import gammapy.irf as irf\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.data import Observation, Observations, DataStore\n",
    "from gammapy.utils.random import get_random_state\n",
    "from gammapy.maps import MapAxis\n",
    "\n",
    "# models modules\n",
    "from gammapy.modeling.models import (\n",
    "    Model,\n",
    "    Models,\n",
    "    SkyModel,\n",
    "    PowerLawSpectralModel,\n",
    "    PowerLawNormSpectralModel,\n",
    "    ExpCutoffPowerLawSpectralModel,\n",
    "    PointSpatialModel,\n",
    "    GaussianSpatialModel,\n",
    "    TemplateSpatialModel,\n",
    "    FoVBackgroundModel,\n",
    "    SpectralModel,\n",
    "    TemplateSpectralModel,\n",
    "    EBLAbsorptionNormSpectralModel,\n",
    "\n",
    ")\n",
    "# dataset modules\n",
    "from gammapy.datasets import (\n",
    "    MapDataset, \n",
    "    MapDatasetOnOff, \n",
    "    MapDatasetEventSampler,\n",
    "    SpectrumDatasetOnOff,\n",
    "    SpectrumDataset, \n",
    "    Datasets,\n",
    "    FluxPointsDataset\n",
    ")\n",
    "\n",
    "from gammapy.maps import MapAxis, WcsGeom, Map, RegionGeom\n",
    "from gammapy.makers import MapDatasetMaker, SpectrumDatasetMaker, ReflectedRegionsBackgroundMaker, WobbleRegionsFinder\n",
    "from gammapy.estimators import FluxPointsEstimator\n",
    "\n",
    "from gammapy.stats.fit_statistics import wstat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72c3084",
   "metadata": {},
   "source": [
    "# LOAD ALPGrid class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4df071-4b0e-4636-bb49-155a9bcca1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from expected_counts import compute_expected_counts, get_array_from_value_and_error, check_keys_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_flare = Observations()\n",
    "for filename in glob.glob(f\"../path/where/the/fits/files/are/stored/flaring_state/*fits\"):\n",
    "    observations_flare.append(Observation.read(filename))\n",
    "\n",
    "observations_post_flare = Observations()\n",
    "for filename in glob.glob(f\"../path/where/the/fits/files/are/stored/post-flaring_state/*fits\"):\n",
    "    observations_post_flare.append(Observation.read(filename)) \n",
    "\n",
    "observations_low_state = Observations()\n",
    "for filename in glob.glob(f\"../path/where/the/fits/files/are/stored/low-state/*fits\"):\n",
    "    observations_low_state.append(Observation.read(filename)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc6048",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( len(observations_flare))\n",
    "print( len(observations_post_flare))\n",
    "print( len(observations_low_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3309c-3fff-4b48-a401-229c3370f1e5",
   "metadata": {},
   "source": [
    "### Function for computing ON/OFF counts from datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7006c-244e-4de0-9a49-030f41494818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Non_Noff_from_obs_list( observations, bkg_maker, on_center, energy_axis ):\n",
    "    \n",
    "    geom             = RegionGeom.create(region=on_center, axes=[energy_axis])\n",
    "    dataset_empty    = SpectrumDataset.create(geom=geom)\n",
    "    dataset_maker    = SpectrumDatasetMaker(containment_correction=False, selection=[\"counts\"])\n",
    "    \n",
    "    n_on  = []\n",
    "    n_off = []\n",
    "    for obs in observations:\n",
    "        dataset                 = dataset_maker.run(dataset_empty.copy(name=f\"{obs.obs_id}\"), obs)\n",
    "        dataset.mask_fit        = dataset.counts.geom.energy_mask(emin, emax)\n",
    "        dataset                 = bkg_maker.run(dataset, obs)\n",
    "        dataset.mask_fit        = dataset.counts.geom.energy_mask(emin, emax)\n",
    "        #datasets.append(dataset)\n",
    "        n_on.append( dataset.counts.data.flatten())\n",
    "        n_off.append( dataset.counts_off.data.flatten())\n",
    "    \n",
    "    n_on  = np.array( n_on )\n",
    "    n_off = np.array( n_off )\n",
    "        \n",
    "    return np.sum(n_on, axis=0,dtype=int), np.sum(n_off, axis=0,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fd8f6-e686-4748-8a20-fd9f1541fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s --> (  B-field, energy, SEDpar )\n",
    "# n --> ( simulations, energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bb8276-2462-4947-bdf0-5e166db04bb6",
   "metadata": {},
   "source": [
    "# DEFINE ENERGY GEOMETRY for each DATASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d56e33f-ad8d-491e-a3b8-5ad3a1e98155",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_true = 200\n",
    "\n",
    "# FLARE\n",
    "emin             = 50*u.GeV\n",
    "emax             = 2.1*u.TeV\n",
    "nbins            = 27     \n",
    "en_edges               = np.geomspace(  emin, emax, nbins) \n",
    "nergy_axis             = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_reco_axis_flare = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_true_axis_flare = MapAxis.from_energy_bounds(5, 5e4, nbin=nbins_true, per_decade=False, unit=\"GeV\", name=\"energy_true\")\n",
    "\n",
    "\n",
    "# POST FLARE\n",
    "emin             = 64*u.GeV\n",
    "emax             = 1.4*u.TeV\n",
    "nbins            = 25    \n",
    "en_edges                    = np.geomspace(  emin, emax, nbins) \n",
    "nergy_axis                  = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_reco_axis_post_flare = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_true_axis_post_flare = MapAxis.from_energy_bounds(5, 5e4, nbin=nbins_true, per_decade=False, unit=\"GeV\", name=\"energy_true\")\n",
    "\n",
    "# LOW STATE\n",
    "emin             = 70*u.GeV\n",
    "emax             = 2.1*u.TeV\n",
    "nbins            = 20     \n",
    "en_edges                   = np.geomspace(  emin, emax, nbins) \n",
    "nergy_axis                 = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_reco_axis_low_state = MapAxis.from_edges(en_edges, interp='log' , unit=\"GeV\", name=\"energy\")\n",
    "energy_true_axis_low_state = MapAxis.from_energy_bounds(5, 5e4, nbin=nbins_true, per_decade=False, unit=\"GeV\", name=\"energy_true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c334f64-bca3-415c-b8d1-325074379016",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70165ce8-cd1a-41b8-b98a-4b90f28c366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of OFF regions to be used to estimate the background\n",
    "n_off_regions = 3\n",
    "alpha         = 1/n_off_regions\n",
    "region_finder = WobbleRegionsFinder(n_off_regions=n_off_regions)\n",
    "bkg_maker = ReflectedRegionsBackgroundMaker(region_finder=region_finder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a4fe6d-1fb2-4f80-aa84-11fbb5eeb58a",
   "metadata": {},
   "source": [
    "### ON REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9506b-c78f-4309-9cec-23a7cb6d6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ON REGION\n",
    "source_coordinates_ngc1275 = SkyCoord.from_name(\"NGC1275\")\n",
    "on_center_ngc1275          = PointSkyRegion(source_coordinates_ngc1275)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2df7c2-39ca-493b-b9a1-ac1dc953c4f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GET N_ON and N_OFF counts per each bin per each DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ad254-df43-4533-ac36-727a9929d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#datasets_flare = get_datasets_from_obs_list\n",
    "n_on_flare, n_off_flare = get_Non_Noff_from_obs_list( observations=observations_flare, on_center=on_center_ngc1275,\n",
    "                                                bkg_maker=bkg_maker,\n",
    "                                                energy_axis=energy_reco_axis_flare)\n",
    "#datasets_post_flare = get_datasets_from_obs_list(\n",
    "n_on_post_flare, n_off_post_flare = get_Non_Noff_from_obs_list(  observations=observations_post_flare,on_center=on_center_ngc1275,\n",
    "                                                bkg_maker=bkg_maker,\n",
    "                                                energy_axis=energy_reco_axis_post_flare)\n",
    "\n",
    "# datasets_low_state = get_datasets_from_obs_list(\n",
    "n_on_low_state, n_off_low_state = get_Non_Noff_from_obs_list(  observations=observations_low_state,on_center=on_center_ngc1275,\n",
    "                                                bkg_maker=bkg_maker,\n",
    "                                                energy_axis=energy_reco_axis_low_state)\n",
    "\n",
    "#datasets_ic310    = get_datasets_from_obs_list( \n",
    "n_on_ic310, n_off_ic310 = get_Non_Noff_from_obs_list( observations=observations_ic310,on_center=on_center_ic310,\n",
    "                                                bkg_maker=bkg_maker,\n",
    "                                                energy_axis=energy_reco_axis_ic310)\n",
    "\n",
    "\n",
    "n_on =  [ n_on_flare,       n_on_post_flare,        n_on_low_state,         n_on_ic310]\n",
    "n_off = [ n_off_flare,       n_off_post_flare,        n_off_low_state,         n_off_ic310]\n",
    "\n",
    "\n",
    "\n",
    "file_name = \"./observed_on_counts.pkl\"\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump( n_on, f)\n",
    "\n",
    "file_name =  \"./observed_off_counts.pkl\"\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(n_off,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bcc3c6-ba93-4e6a-9642-3d5b54ef6bfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SIMULATE N_ON and N_OFF counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ee114-85d8-4e2e-95d8-33a1d22da619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp_signal_counts_from_obs_list( true_flux, observations, source_coord, ereco,etrue, delta_ereco, delta_etrue):\n",
    "    \n",
    "    delta_etrue = delta_etrue[None,None,:] \n",
    "    delta_ereco = delta_ereco[None,:]\n",
    "    \n",
    "    IRF  = np.zeros( (len(ereco),len(etrue)) ) * u.m**2 * u.s/u.GeV\n",
    "    for obs in observations:\n",
    "        true_offset = obs.pointing_radec.separation( source_coord)\n",
    "        IRF        += get_IRF( obs, true_offset, ereco,etrue)\n",
    "               \n",
    "    obs_flux           = np.sum( true_flux[:,None,:]*IRF[None,:,:]*delta_etrue,axis=2)\n",
    "    obs_flux           = obs_flux.to(1/( u.GeV  ))\n",
    "    exp_signal_counts  = obs_flux*delta_ereco\n",
    "        \n",
    "\n",
    "    return np.array( exp_signal_counts.to('').value)# dtype=np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd08565-9c37-40bf-a3b0-a4fcdd0f28c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from expected_counts import get_IRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6e1ed-d0f9-4c05-8f9c-66c49c58c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "dominguez = EBLAbsorptionNormSpectralModel.read_builtin(\"dominguez\", redshift=0.01790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1badd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ABSORPTION\n",
    "list_of_names_gm = []\n",
    "path_name = \"/path/where/your/npy/files/from/ALPs/absorption/are/stored\" \n",
    "for name in glob.glob(path_name+\"/*.npy\"):  \n",
    "    i_seed = 0\n",
    "    np.random.seed(i_seed)\n",
    "    \n",
    "    #i.e.\n",
    "    #name =  '../ngc1275_100real_m_464_g_229_.npy'\n",
    "    \n",
    "    names_split = str.split(name, \"_\")\n",
    "    g = names_split[-2]\n",
    "    m = names_split[-4]\n",
    "    g = float(g) * 1e-14 / u.GeV\n",
    "    m = float(m) * 1e-2 * u.neV\n",
    "    \n",
    "        \n",
    "    total_number_of_simulations = 100\n",
    "    number_of_B_field_realizations = 100\n",
    "    list_of_B_field = np.arange(number_of_B_field_realizations)\n",
    "    \n",
    "    \n",
    "    # FLARE\n",
    "    np.random.seed(i_seed)\n",
    "    p_gamma_gamma = []\n",
    "    for i in list_of_B_field:\n",
    "        en_absorp_array     = np.load(name)\n",
    "        energy              = en_absorp_array[0] * u.GeV\n",
    "        values              = en_absorp_array[1+i] * u.Unit(\"\")\n",
    "        absorption          = TemplateSpectralModel(energy, values)\n",
    "        p_gamma_gamma.append( absorption( energy_true_axis_flare.center).to('').value )\n",
    "    p_gamma_gamma       = np.array(p_gamma_gamma)\n",
    "    \n",
    "    reference =0.3 * u.TeV\n",
    "    amplitude = 16.1e-10 * u.Unit(\"TeV-1 cm-2 s-1\")\n",
    "    index     = 2.11\n",
    "    lambda_   = 1.24 * u.Unit(\"TeV-1\")\n",
    "    energies  = energy_true_axis_flare.center\n",
    "    true_flux = amplitude*(energies/reference)**(-index) * np.exp(-energies*lambda_) \n",
    "    true_flux = true_flux[None,:] * p_gamma_gamma\n",
    "    exp_signals_flare = get_exp_signal_counts_from_obs_list( \n",
    "                                        true_flux    = true_flux, \n",
    "                                        observations = observations_flare, \n",
    "                                        source_coord = source_coordinates_ngc1275, \n",
    "                                        ereco        = energy_reco_axis_flare.center,  \n",
    "                                        etrue        = energy_true_axis_flare.center, \n",
    "                                        delta_ereco  = energy_reco_axis_flare.bin_width,\n",
    "                                        delta_etrue  = energy_true_axis_flare.bin_width,\n",
    "                                                     )\n",
    "    \n",
    "    # SIMULATE N_ON and N_OFF from the expected signal counts\n",
    "    np.random.seed(i_seed)\n",
    "    n_signal          =  np.random.poisson( exp_signals_flare) \n",
    "    assumed_b         =  np.reshape( np.repeat( n_off_flare, total_number_of_simulations), (len(n_off_flare),total_number_of_simulations)).T\n",
    "    np.random.seed(i_seed)\n",
    "    n_b_on            =  np.random.poisson(assumed_b/3) ### 3 is the number of OFF regions used to estimate the background\n",
    "    n_on_fake_flare   =  n_signal + n_b_on\n",
    "    np.random.seed(i_seed)\n",
    "    n_off_fake_flare  =  np.random.poisson(assumed_b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # POST FLARE\n",
    "    np.random.seed(i_seed)\n",
    "    p_gamma_gamma = []\n",
    "    for i in list_of_B_field:\n",
    "        en_absorp_array     = np.load(name)\n",
    "        energy              = en_absorp_array[0] * u.GeV\n",
    "        values              = en_absorp_array[1+i] * u.Unit(\"\") \n",
    "        absorption          = TemplateSpectralModel(energy, values)\n",
    "        p_gamma_gamma.append( absorption( energy_true_axis_post_flare.center).to('').value )\n",
    "    p_gamma_gamma       = np.array(p_gamma_gamma)\n",
    "    \n",
    "    reference = 0.3 * u.TeV\n",
    "    amplitude = 11.4e-10 * u.Unit(\"TeV-1 cm-2 s-1\")\n",
    "    index     = 1.79\n",
    "    lambda_   = 3.45 * u.Unit(\"TeV-1\")\n",
    "    energies  = energy_true_axis_post_flare.center\n",
    "    true_flux = amplitude*(energies/reference)**(-index) * np.exp(-energies*lambda_) \n",
    "    true_flux = true_flux[None,:] * p_gamma_gamma\n",
    "    exp_signals_post_flare = get_exp_signal_counts_from_obs_list( \n",
    "                                        true_flux    = true_flux, \n",
    "                                        observations = observations_post_flare, \n",
    "                                        source_coord = source_coordinates_ngc1275, \n",
    "                                        ereco        = energy_reco_axis_post_flare.center,  \n",
    "                                        etrue        = energy_true_axis_post_flare.center, \n",
    "                                        delta_ereco  = energy_reco_axis_post_flare.bin_width,\n",
    "                                        delta_etrue  = energy_true_axis_post_flare.bin_width,\n",
    "                                                     )\n",
    "    # SIMULATE N_ON and N_OFF from the expected signal counts\n",
    "    np.random.seed(i_seed)\n",
    "    n_signal               =  np.random.poisson( exp_signals_post_flare) \n",
    "    assumed_b              =  np.reshape( np.repeat( n_off_post_flare, total_number_of_simulations), (len(n_off_post_flare),total_number_of_simulations)).T\n",
    "    np.random.seed(i_seed)\n",
    "    n_b_on                 =  np.random.poisson(assumed_b/3)\n",
    "    n_on_fake_post_flare   =  n_signal + n_b_on\n",
    "    np.random.seed(i_seed)\n",
    "    n_off_fake_post_flare  =  np.random.poisson(assumed_b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # LOW STATE\n",
    "    np.random.seed(i_seed)\n",
    "    p_gamma_gamma = []\n",
    "    for i in list_of_B_field:\n",
    "        en_absorp_array     = np.load(name)\n",
    "        energy              = en_absorp_array[0] * u.GeV\n",
    "        values              = en_absorp_array[1+i] * u.Unit(\"\") # whatever numer from 1 to 100\n",
    "        absorption          = TemplateSpectralModel(energy, values)\n",
    "        p_gamma_gamma.append( absorption( energy_true_axis_low_state.center).to('').value )\n",
    "    p_gamma_gamma       = np.array(p_gamma_gamma)\n",
    "    \n",
    "    reference = 0.3 * u.TeV\n",
    "    amplitude = 1.1e-10 * u.Unit(\"TeV-1 cm-2 s-1\")\n",
    "    index     = 2.54\n",
    "    lambda_   = 2 * u.Unit(\"TeV-1\")\n",
    "    energies  = energy_true_axis_low_state.center\n",
    "    true_flux = amplitude*(energies/reference)**(-index) * np.exp(-energies*lambda_) \n",
    "    true_flux = true_flux[None,:] * p_gamma_gamma\n",
    "    exp_signals_low_state = get_exp_signal_counts_from_obs_list( \n",
    "                                        true_flux    = true_flux, \n",
    "                                        observations = observations_low_state, \n",
    "                                        source_coord = source_coordinates_ngc1275, \n",
    "                                        ereco        = energy_reco_axis_low_state.center,  \n",
    "                                        etrue        = energy_true_axis_low_state.center, \n",
    "                                        delta_ereco  = energy_reco_axis_low_state.bin_width,\n",
    "                                        delta_etrue  = energy_true_axis_low_state.bin_width,\n",
    "                                                     )\n",
    "    # SIMULATE N_ON and N_OFF from the expected signal counts\n",
    "    np.random.seed(i_seed)\n",
    "    n_signal              =  np.random.poisson( exp_signals_low_state) \n",
    "    assumed_b             =  np.reshape( np.repeat( n_off_low_state, total_number_of_simulations), (len(n_off_low_state),total_number_of_simulations)).T\n",
    "    np.random.seed(i_seed)\n",
    "    n_b_on                =  np.random.poisson(assumed_b/3)\n",
    "    n_on_fake_low_state   =  n_signal + n_b_on\n",
    "    np.random.seed(i_seed)\n",
    "    n_off_fake_low_state  =  np.random.poisson(assumed_b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################\n",
    "    \n",
    "    \n",
    "    n_on = []\n",
    "    n_off = []\n",
    "    for i in range(100):\n",
    "        n_on.append( [ n_on_fake_flare[i],       n_on_fake_post_flare[i],        n_on_fake_low_state[i]])\n",
    "        n_off.append( [ n_off_fake_flare[i],       n_off_fake_post_flare[i],        n_off_fake_low_state[i]])\n",
    "    name_m = str(int(m.to(0.01*u.neV).value))\n",
    "    name_g = str(int(g.to( 1e-14 /u.GeV).value))\n",
    "\n",
    "    ### Prior to this step, create the folder for storing the files with ON and OFF counts, i.e. \"fake_on_off_counts\"\n",
    "    \n",
    "    file_name = \"./fake_on_off_counts/fake_on_counts_\"+name_m+\"__\"+name_g+\"_.pkl\"\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump( n_on, f)\n",
    "        \n",
    "    file_name = \"./fake_on_off_counts/fake_off_counts_\"+name_m+\"__\"+name_g+\"_.pkl\"\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(n_off,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6712fb6d-8f65-4436-a9c6-5c3a627ee46b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GET THE EXPECTED SIGNAL COUNTS per each bin and per each DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a9fef-d4ba-4ba7-93b1-12e5bbadf8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 0\n",
    "\n",
    "\n",
    "path_name = \"/path/where/your/npy/files/from/ALPs/absorption/are/stored\" \n",
    "\n",
    "    \n",
    "for name in glob.glob(path_name+\"/*.npy\"): \n",
    "    ## GET INFO ON M AND G FROM FILE NAME\n",
    "    names_split = str.split(name, \"_\")\n",
    "    \n",
    "    g = names_split[-2]\n",
    "    m = names_split[-4]\n",
    "    g = float(g) * 1e-14 / u.GeV\n",
    "    m = float(m) * 1e-2 * u.neV\n",
    "    \n",
    "        \n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "total_s = compute_expected_counts(name)\n",
    "\n",
    "### Prior to this step, create the folder for storing the files with expected counts, i.e. \"expected_counts\"\n",
    "\n",
    "    for k in range(4):\n",
    "        name_m = str(int(m.to(0.01*u.neV).value))\n",
    "        name_g = str(int(g.to( 1e-14 /u.GeV).value))\n",
    "        file_name = \"./expected_counts/expected_counts_\"+name_m+\"__\"+name_g+\"_\"+str(k)+\"_array.npy.gz\"\n",
    "\n",
    "        with gzip.open(file_name, 'wb') as f:\n",
    "            np.save(f, total_s[k])\n",
    "            \n",
    "    i +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
